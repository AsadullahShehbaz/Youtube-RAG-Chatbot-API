"""
API routes for the YouTube RAG chatbot.
"""
from fastapi import APIRouter, HTTPException
from app.models.schemas import QueryRequest, QueryResponse, HealthResponse
from app.services.transcript_service import TranscriptService
from app.services.vectorstore_service import VectorStoreService
from app.services.llm_service import LLMService
from app.core.logging_config import logger

# Create router
router = APIRouter()

# Initialize services (singleton pattern)
transcript_service = TranscriptService()
vectorstore_service = VectorStoreService()
llm_service = LLMService()


@router.get("/", response_model=HealthResponse, tags=["Health"])
async def root():
    """Root endpoint - health check."""
    logger.info("Root health check endpoint called")
    return HealthResponse(
        status="healthy",
        message="YouTube RAG Chatbot API is running"
    )


@router.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check():
    """Detailed health check endpoint."""
    logger.info("Detailed health check endpoint called")
    return HealthResponse(
        status="healthy",
        message="All systems operational"
    )


@router.post("/ask", response_model=QueryResponse, tags=["Chat"])
async def ask_question(payload: QueryRequest):
    """
    Ask a question about a YouTube video.
    
    This endpoint:
    1. Extracts video ID from URL (or accepts direct video ID)
    2. Fetches the transcript from YouTube
    3. Creates a vector store from the transcript
    4. Retrieves relevant context for the question
    5. Generates an answer using LLM
    """
    try:
        video_url = payload.video_url
        logger.info(f"Received /ask request for video_url={video_url}, question='{payload.question}'")

        # Step 1: Fetch transcript
        transcript = transcript_service.fetch_transcript(video_url)
        logger.info(f"Step 1 completed: Transcript fetched (length={len(transcript)} characters)")

        # Step 2: Create vector store
        vectorstore = vectorstore_service.create_vectorstore(transcript)
        logger.info("Step 2 completed: Vector store created")

        # Step 3: Retrieve relevant documents
        retrieved_docs = vectorstore_service.retrieve_documents(
            vectorstore,
            payload.question
        )
        logger.info(f"Step 3 completed: Retrieved {len(retrieved_docs)} relevant documents")

        # Step 4: Format context and generate answer
        context = llm_service.format_documents(retrieved_docs)
        answer = llm_service.generate_answer(context, payload.question)
        logger.info("Step 4 completed: Answer generated by LLM")

        return QueryResponse(
            answer=answer,
            video_url=video_url
        )
        
    except HTTPException as http_err:
        logger.warning(f"HTTPException raised during /ask request: {http_err.detail}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error in /ask endpoint: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Internal server error: {str(e)}"
        )
